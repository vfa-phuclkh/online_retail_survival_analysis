{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A case-study for applying Survival Analysis on real businessÂ problem.\n",
    "This notebook contains the sample implementation of idea discussed in this article: https://medium.com/vitalify-asia/a-case-study-for-applying-survival-analysis-on-real-business-problem-844e20820a7\n",
    "\n",
    "The data files in this repo is only a subset of the data used in the example and only serves as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import datetime\n",
    "from time import mktime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "seed = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_base_df():\n",
    "    df = pd.read_csv('input_orig.csv')\n",
    "    df['Purchase_Date'] = pd.to_datetime(df['Purchase_Date'], format='%y/%m/%d').astype(int)\n",
    "    df['Price_down_date'] = pd.to_datetime(df['Price_down_date'], format='%y/%m/%d').astype(int)\n",
    "    df['Departure_Date'] = pd.to_datetime(df['Departure_Date'], format='%y/%m/%d').astype(int)\n",
    "    # Remove invalid month. It contains 10 rows.\n",
    "#     df = df[df['Reg_Month'] != '-']\n",
    "#     df['Reg_Date'] = df.apply(_make_reg_date, axis=1)\n",
    "    df = pd.get_dummies(df, drop_first=True, columns=[\n",
    "        'Color',\n",
    "        'Country_Sold'\n",
    "    ])\n",
    "    df = df.drop([\n",
    "#         'Reg_Year',\n",
    "#         'Reg_Month',\n",
    "    ], axis=1)\n",
    "#     df = df[df.Publish_period <= 80]\n",
    "    return df\n",
    "\n",
    "def _load_data():\n",
    "    df = load_base_df()\n",
    "\n",
    "    y = df['Publish_period'].values\n",
    "    X = df.drop(['Publish_period'], axis=1).values\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def list_feature_names():\n",
    "    df = load_base_df()\n",
    "    return df.drop(['Publish_period'], axis=1).columns.values\n",
    "\n",
    "def load_train_data():\n",
    "    \"\"\"\n",
    "    :return: X : train inputs\n",
    "    :return: y : train labels\n",
    "    \"\"\"\n",
    "    X, y = _load_data()\n",
    "\n",
    "    y_labels = np.zeros_like(y)\n",
    "    y_labels[y >= np.percentile(y, 25)] = 1\n",
    "    y_labels[y >= np.percentile(y, 50)] = 2\n",
    "    y_labels[y >= np.percentile(y, 75)] = 3\n",
    "\n",
    "    X_tr, X_test, y_tr, y_test = train_test_split(X, y,\n",
    "                                                  stratify=y_labels,\n",
    "                                                  shuffle=True,\n",
    "                                                  random_state=seed,\n",
    "                                                  test_size=0.2,\n",
    "                                                  )\n",
    "\n",
    "    return X_tr, y_tr, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, y_tr, X_test, y_test = load_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = X_tr[0][1]\n",
    "print(datetime.datetime.fromtimestamp(1440115200000000000/1e9).strftime('%y/%m/%d'))\n",
    "X_tr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_tr.shape, X_test.shape)\n",
    "print(\"List of all feature names:\")\n",
    "name_list = list_feature_names()\n",
    "for i in range(name_list.shape[0]):\n",
    "    print(i, name_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "from sklearn.preprocessing import normalize\n",
    "X_tr[:, 1:] = normalize(X_tr[:, 1:], axis=0)\n",
    "X_test[:, 1:] = normalize(X_test[:, 1:], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Simple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "eval_result = {}\n",
    "params = {\n",
    "    'bagging_fraction': 0.8351240299610244,\n",
    "    'feature_fraction': 0.9880900755129445,\n",
    "    'learning_rate': 0.601638071095316,\n",
    "    'max_bin': 733,\n",
    "    'max_depth': 7,\n",
    "    'num_leaves': 12,\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'auc'},\n",
    "    'verbose': -1,\n",
    "}\n",
    "\n",
    "lgb_tr = lgb.Dataset(X_tr[:, 1:], label=y_tr, free_raw_data=False)\n",
    "lgb_val = lgb.Dataset(X_test[:, 1:], label=y_test, reference=lgb_tr, free_raw_data=False)\n",
    "\n",
    "model = lgb.train(params,\n",
    "                  lgb_tr,\n",
    "                  num_boost_round=2000,\n",
    "                  valid_sets=lgb_val,\n",
    "                  early_stopping_rounds=100,\n",
    "                  evals_result=eval_result,\n",
    "                  verbose_eval=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preds = model.predict(X_tr[: ,1:], num_iteration=model.best_iteration)\n",
    "loss = mean_squared_error(y_tr, preds)\n",
    "print(\"Mean square error: \", loss)\n",
    "\n",
    "sort_y = np.argsort(y_tr)\n",
    "plt.plot(preds[sort_y], label='predictions')\n",
    "plt.plot(y_tr[sort_y], label='X_tr')\n",
    "plt.xlabel('bike')\n",
    "plt.ylabel('day t')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test[: ,1:], num_iteration=model.best_iteration)\n",
    "loss = mean_squared_error(y_test, preds)\n",
    "print(\"Mean square error: \", loss)\n",
    "\n",
    "sort_y = np.argsort(y_test)\n",
    "plt.plot(preds[sort_y], label='predictions')\n",
    "plt.plot(y_test[sort_y], label='X_test')\n",
    "plt.xlabel('bike')\n",
    "plt.ylabel('day t')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([X_tr, X_test], axis=0)\n",
    "y = np.concatenate([y_tr, y_test], axis=0)\n",
    "\n",
    "preds = model.predict(X[: ,1:], num_iteration=model.best_iteration)\n",
    "loss = mean_squared_error(y, preds)\n",
    "print(\"Mean square error: \", loss)\n",
    "\n",
    "sort_y = np.argsort(y)\n",
    "plt.plot(preds[sort_y], label='Predictions')\n",
    "plt.plot(y[sort_y], label='Ground truth')\n",
    "plt.xlabel('bike')\n",
    "plt.ylabel('Publish_period')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Survival Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load survival-format data\n",
    "df = pd.read_csv('input_survival.csv')\n",
    "df = pd.get_dummies(df, drop_first=True, columns=[\n",
    "        'Color',\n",
    "        'Country_Sold'\n",
    "    ])\n",
    "X = df.drop(['is_sold', 'Publish_period'], axis=1)\n",
    "X_values = X.values\n",
    "# Combine the event indicator isSold and Publish_period to create ground truth y for our model\n",
    "isSold = df['is_sold'].astype(bool)\n",
    "pub = df['Publish_period']\n",
    "y = pd.concat([isSold, pub], axis=1)\n",
    "y_values = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "from sklearn.preprocessing import normalize\n",
    "X_values[:, 1:] = normalize(X_values[:, 1:], axis=0)\n",
    "\n",
    "# train test split\n",
    "X_tr, X_test, y_tr, y_test = train_test_split(X_values, y_values,\n",
    "                                                  shuffle=True,\n",
    "                                                  random_state=seed,\n",
    "                                                  test_size=0.2,\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y to uncensored data, all are (True, days)\n",
    "dt = np.dtype([('event', np.bool_), ('days', np.float64)])\n",
    "def convert_y(y):\n",
    "    y_out = []\n",
    "#     y = np.log(y+1e-22)\n",
    "    for i in range(y.shape[0]):\n",
    "        if y[i, 0]:\n",
    "            y_out.append(('True', y[i, 1]))\n",
    "        else:\n",
    "            y_out.append(('False', y[i, 1]))\n",
    "    y_out = np.array(y_out, dtype=dt)\n",
    "    return y_out\n",
    "\n",
    "y_converted = convert_y(y_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.nonparametric import kaplan_meier_estimator\n",
    "\n",
    "time, sold_prob = kaplan_meier_estimator(y['is_sold'], y['Publish_period'])\n",
    "plt.step(time, sold_prob, where=\"post\")\n",
    "plt.ylabel(\"est. probability of survival $\\hat{S}(t)$\")\n",
    "plt.xlabel(\"day $t$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Price\n",
    "avg_price = np.mean(X['Price'])\n",
    "print(avg_price)\n",
    "\n",
    "mask_price_below = X['Price'] <= avg_price\n",
    "time, sold_prob_below = kaplan_meier_estimator(\n",
    "    y['is_sold'][mask_price_below],\n",
    "    y[\"Publish_period\"][mask_price_below])\n",
    "plt.step(time, sold_prob_below, where=\"post\", label=\"price<=avg\")\n",
    "\n",
    "mask_price_above = X['Price'] > avg_price\n",
    "time, sold_prob_above = kaplan_meier_estimator(\n",
    "    y['is_sold'][mask_price_above],\n",
    "    y[\"Publish_period\"][mask_price_above])\n",
    "plt.step(time, sold_prob_above, where=\"post\", label=\"price>avg\")\n",
    "\n",
    "plt.ylabel(\"est. probability of survival $\\hat{S}(t)$\")\n",
    "plt.xlabel(\"time $t$\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the N_Photos\n",
    "avg_price = np.mean(X['N_Photos'])\n",
    "print(avg_price)\n",
    "\n",
    "mask_price_below = X['N_Photos'] <= avg_price\n",
    "time, sold_prob_below = kaplan_meier_estimator(\n",
    "    y['is_sold'][mask_price_below],\n",
    "    y[\"Publish_period\"][mask_price_below])\n",
    "plt.step(time, sold_prob_below, where=\"post\", label=\"price<=avg\")\n",
    "\n",
    "mask_price_above = X['N_Photos'] >= avg_price\n",
    "time, sold_prob_above = kaplan_meier_estimator(\n",
    "    y['is_sold'][mask_price_above],\n",
    "    y[\"Publish_period\"][mask_price_above])\n",
    "plt.step(time, sold_prob_above, where=\"post\", label=\"price>avg\")\n",
    "\n",
    "plt.ylabel(\"est. probability of survival $\\hat{S}(t)$\")\n",
    "plt.xlabel(\"time $t$\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Survival Models\n",
    "#### Train only one of the model below before predict\n",
    "### CoxPHSurvivalAnalysis\n",
    "The CoxPHSurvivalAnalysis expects a data matrix and a structered array of survival times and binary event indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "\n",
    "estimator = CoxPHSurvivalAnalysis(alpha=2e-01, tol=1e-09, n_iter=1000)\n",
    "estimator.fit(X_values[:, 1:], y_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.metrics import concordance_index_censored\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def predict_day(pred_survival, prob=0.5):\n",
    "    days = np.zeros((pred_survival.shape))\n",
    "    for i, c in enumerate(pred_survival):\n",
    "        days[i] = c.x[-1]\n",
    "        for j, prob in enumerate(c.y):\n",
    "            if prob >= 0.5:\n",
    "                days[i] = c.x[j]\n",
    "    return days\n",
    "\n",
    "def score_survival_model(model, X, y_out):\n",
    "    y = np.zeros((y_out.shape))\n",
    "    for i in range(y_out.shape[0]):\n",
    "        y[i] = y_out[i][1]\n",
    "    prediction = model.predict_survival_function(X)\n",
    "    predict_days = predict_day(prediction)\n",
    "    loss = mean_squared_error(y, predict_days)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_survival = estimator.predict_survival_function(X_test[:, 1:].astype(float))\n",
    "for i, c in enumerate(pred_survival):\n",
    "    plt.step(c.x, c.y, where=\"post\", label=\"Sample %d\" % (i + 1))\n",
    "plt.ylabel(\"est. probability of survival $\\hat{S}(t)$\")\n",
    "plt.xlabel(\"time $t$\")\n",
    "# plt.legend(loc=\"best\")\n",
    "plt.title(\"Survival function\")\n",
    "plt.figure(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_days = predict_day(pred_survival)\n",
    "predict_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = y_test.shape\n",
    "plt.plot(predict_days, label='predictions')\n",
    "plt.plot(y_test, label='X_test')\n",
    "plt.xlabel('car')\n",
    "plt.ylabel('day t')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "loss = mean_squared_error(y_test[:, 1], predict_days)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggest price for maximum profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some import\n",
    "from time import mktime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COST_PER_DAY = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_profit(df_record, estimator, scaler):\n",
    "    scaled = scaler.transform(df_record.drop(['Bike_id', 'Publish_period']).values.reshape(1, -1))\n",
    "    sf = estimator.predict_survival_function([scaled])[0]\n",
    "\n",
    "    # Interpolation\n",
    "    f2 = interp1d(sf.x, sf.y, kind='cubic')\n",
    "    x = np.arange(np.max(sf.x) + 1)\n",
    "    y = f2(x)\n",
    "\n",
    "    income = (-np.gradient(y, x) * df_record['Price']).sum()\n",
    "    outcome = (COST_PER_DAY * y).sum()\n",
    "    profit = income - outcome\n",
    "\n",
    "    return profit\n",
    "\n",
    "def plot_survival(estimator, X, n_plot=-1):\n",
    "    pred_survival = estimator.predict_survival_function(X)\n",
    "    for i, c in enumerate(pred_survival[:n_plot]):\n",
    "        plt.step(c.x, c.y, where=\"post\", label=\"Sample %d\" % (i + 1))\n",
    "    plt.ylabel(\"est. probability of survival $\\hat{S}(t)$\")\n",
    "    plt.xlabel(\"time $t$\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.title(\"Survival function\")\n",
    "    plt.show()\n",
    "    \n",
    "def optimize_price(estimator, scaler, df_record, max_price, min_price):\n",
    "    print(df_record)\n",
    "    price = df_record['Price']\n",
    "    sp_price = np.linspace(min_price, max_price, 1000)\n",
    "\n",
    "    profits = []\n",
    "    for p in sp_price:\n",
    "        df_record['Price'] = p\n",
    "        profit = calc_profit(df_record, estimator, scaler)\n",
    "        profits.append(profit)\n",
    "    best = np.argmax(profits)\n",
    "    best_profit = profits[best]\n",
    "    best_price = sp_price[best]\n",
    "    print(\"Suggest price:\", best_price)\n",
    "    print(\"price:\", price)\n",
    "    plt.plot(sp_price, profits)\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "df = pd.read_csv('input_survival.csv')\n",
    "df = pd.get_dummies(df, drop_first=True, columns=[\n",
    "        'Color',\n",
    "        'Country_Sold'\n",
    "    ])\n",
    "X = df.drop(['is_sold', 'Publish_period'], axis=1)\n",
    "y = df['Publish_period'].values\n",
    "\n",
    "ref_tr, ref_val, _, _ = train_test_split(df['Bike_id'].values, y,\n",
    "#                                          stratify=y_labels,\n",
    "                                         shuffle=True,\n",
    "                                         random_state=123,\n",
    "                                         test_size=0.2,\n",
    "                                         )\n",
    "df_tr = df[df['Bike_id'].isin(ref_tr)]\n",
    "df_val = df[df['Bike_id'].isin(ref_val)]\n",
    "\n",
    "# Prepare X\n",
    "scaler = MinMaxScaler().fit(df.drop(['Bike_id', 'Publish_period'], axis=1).values)\n",
    "X_tr = scaler.transform(df_tr.drop(['Bike_id', 'Publish_period'], axis=1).values)\n",
    "X_val = scaler.transform(df_val.drop(['Bike_id', 'Publish_period'], axis=1).values)\n",
    "\n",
    "# Prepare y\n",
    "y_tr = pd.DataFrame({\n",
    "    'Survival_in_days': df_tr['Publish_period'].values,\n",
    "    'Status': np.ones_like(df_tr['Publish_period'].values).astype(bool),\n",
    "}).to_records(index=False)\n",
    "y_val = pd.DataFrame({\n",
    "    'Survival_in_days': df_val['Publish_period'].values,\n",
    "    'Status': np.ones_like(df_val['Publish_period'].values).astype(bool),\n",
    "}).to_records(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('input_survival.csv')\n",
    "df = pd.get_dummies(df, drop_first=True, columns=[\n",
    "        'Color',\n",
    "        'Country_Sold'\n",
    "    ])\n",
    "X = df.drop(['is_sold', 'Publish_period'], axis=1)\n",
    "X_values = X.values\n",
    "# Combine the event indicator isSold and Publish_period to create ground truth y for our model\n",
    "isSold = df['is_sold'].astype(bool)\n",
    "pub = df['Publish_period']\n",
    "y = pd.concat([isSold, pub], axis=1)\n",
    "y_values = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare X\n",
    "scaler = MinMaxScaler().fit(df.drop(['Bike_id', 'Publish_period'], axis=1).values)\n",
    "X_tr = scaler.transform(df_tr.drop(['Bike_id', 'Publish_period'], axis=1).values)\n",
    "X_val = scaler.transform(df_val.drop(['Bike_id', 'Publish_period'], axis=1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit\n",
    "estimator = CoxPHSurvivalAnalysis(alpha=3, n_iter=100)\n",
    "estimator.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot survival\n",
    "plot_survival(estimator, X_val, n_plot=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_price = X['Price'].values.max()\n",
    "min_price = X['Price'].values.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print one sample at index 10\n",
    "optimize_price(estimator, scaler, df_val.iloc[5], max_price, min_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
